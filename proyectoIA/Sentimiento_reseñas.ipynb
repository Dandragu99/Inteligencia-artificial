{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3643544b-2fe2-4b63-93bd-764c3afbb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabd24f4-70e9-4328-8d83-5d8075d13da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Entendimiento de los datos\n",
    "# Carga del dataset\n",
    "df_train = pd.read_csv(\"C:/Users/Dragu/PycharmProjects/proyectoIA/src/archive/Train.csv\")\n",
    "df_test = pd.read_csv(\"C:/Users/Dragu/PycharmProjects/proyectoIA/src/archive/Test.csv\")\n",
    "df_valid = pd.read_csv(\"C:/Users/Dragu/PycharmProjects/proyectoIA/src/archive/Valid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48e0864-8bc1-4a65-91f3-fffd033077c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    50000 non-null  object\n",
      " 1   label   50000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 781.4+ KB\n",
      "None\n",
      "                                                text  label\n",
      "0  I grew up (b. 1965) watching and loving the Th...      0\n",
      "1  When I put this movie in my DVD player, and sa...      0\n",
      "2  Why do people who do not know what a particula...      0\n",
      "3  Even though I have great interest in Biblical ...      0\n",
      "4  Im a die hard Dads Army fan and nothing will e...      1\n",
      "Index(['text', 'label'], dtype='object')\n",
      "label\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Unir los datasets en uno solo\n",
    "df_review = pd.concat([df_train, df_test, df_valid], ignore_index=True)\n",
    "\n",
    "# Mostrar información del dataset\n",
    "print(df_review.info())\n",
    "print(df_review.head())\n",
    "# Ver nombres de las columnas antes de usarlas\n",
    "print(df_review.columns)\n",
    "print(df_review['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7f6bf86-4d65-4834-ba25-85cc5b83221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    25000\n",
      "1    25000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Preparación de los datos\n",
    "# Balanceo de datos usando RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_bal, y_bal = rus.fit_resample(df_review[['text']], df_review['label'])\n",
    "\n",
    "# Convertimos a DataFrame\n",
    "df_review_bal = pd.DataFrame({'review': X_bal['text'], 'sentiment': y_bal})\n",
    "\n",
    "print(df_review_bal['sentiment'].value_counts())\n",
    "\n",
    "# División en train y test\n",
    "train, test = train_test_split(df_review_bal, test_size=0.33, random_state=42)\n",
    "train_x, train_y = train['review'], train['sentiment']\n",
    "test_x, test_y = test['review'], test['sentiment']\n",
    "\n",
    "# Vectorización TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "train_x_vector = tfidf.fit_transform(train_x)\n",
    "test_x_vector = tfidf.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e9bba-7a77-452b-87e2-df07a89f4a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Modelado\n",
    "models = {\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train_x_vector, train_y)  # Entrenamos el modelo\n",
    "    accuracy = model.score(test_x_vector, test_y)  # Evaluamos el modelo\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e598715-9623-4a29-a74a-4e3ef8fe846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Evaluación\n",
    "svc = models[\"SVM\"]\n",
    "predictions = svc.predict(test_x_vector)\n",
    "print(classification_report(test_y, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08da11-e6ad-4153-bb26-728b8e953603",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(test_y, predictions, labels=[1, 0])  # Si las etiquetas son 1 y 0\n",
    "sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['positive', 'negative'], yticklabels=['positive', 'negative'])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82f302-9cf0-442f-89ee-5c734cea1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo SVM entrenado sin GridSearch\n",
    "joblib.dump(models[\"SVM\"], \"modelo_svm.pkl\")\n",
    "\n",
    "# Guardar el vectorizador TF-IDF\n",
    "joblib.dump(tfidf, \"vectorizador_tfidf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca94f44-2f4c-4c1c-af51-9042967e5d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
